{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b26591d9-3fc4-4a1a-aecd-3abcbc252bc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting awscli\n",
      "  Downloading awscli-1.32.14-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting botocore==1.34.14 (from awscli)\n",
      "  Downloading botocore-1.34.14-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting docutils<0.17,>=0.10 (from awscli)\n",
      "  Downloading docutils-0.16-py2.py3-none-any.whl (548 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m548.2/548.2 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting s3transfer<0.11.0,>=0.10.0 (from awscli)\n",
      "  Downloading s3transfer-0.10.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: PyYAML<6.1,>=3.10 in /usr/local/lib/python3.10/dist-packages (from awscli) (6.0.1)\n",
      "Collecting colorama<0.4.5,>=0.2.5 (from awscli)\n",
      "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
      "Collecting rsa<4.8,>=3.1.2 (from awscli)\n",
      "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from botocore==1.34.14->awscli)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore==1.34.14->awscli) (2.8.2)\n",
      "Requirement already satisfied: urllib3<2.1,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore==1.34.14->awscli) (1.26.13)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<4.8,>=3.1.2->awscli)\n",
      "  Downloading pyasn1-0.5.1-py2.py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore==1.34.14->awscli) (1.16.0)\n",
      "Downloading awscli-1.32.14-py3-none-any.whl (4.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading botocore-1.34.14-py3-none-any.whl (11.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading s3transfer-0.10.0-py3-none-any.whl (82 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.9/84.9 kB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyasn1, jmespath, docutils, colorama, rsa, botocore, s3transfer, awscli\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install awscli\n",
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f21ac79a-6509-414b-9204-5307cc928160",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/transformers.git\n",
      "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-7p1ze35f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-7p1ze35f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Resolved https://github.com/huggingface/transformers.git to commit 3eddda1111f70f3a59485e08540e8262b927e867\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (3.9.0)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers==4.37.0.dev0)\n",
      "  Downloading huggingface_hub-0.20.2-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers==4.37.0.dev0)\n",
      "  Downloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (2.31.0)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers==4.37.0.dev0)\n",
      "  Downloading tokenizers-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.3.1 (from transformers==4.37.0.dev0)\n",
      "  Downloading safetensors-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tqdm>=4.27 (from transformers==4.37.0.dev0)\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.0.dev0)\n",
      "  Downloading fsspec-2023.12.2-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.0.dev0) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.0.dev0) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.0.dev0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.0.dev0) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.0.dev0) (2022.12.7)\n",
      "Downloading huggingface_hub-0.20.2-py3-none-any.whl (330 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.3/330.3 kB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.0/774.0 kB\u001b[0m \u001b[31m130.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m127.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m161.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2023.12.2-py3-none-any.whl (168 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.0/169.0 kB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: transformers\n",
      "  Building wheel for transformers (pyproject.toml): started\n",
      "  Building wheel for transformers (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for transformers: filename=transformers-4.37.0.dev0-py3-none-any.whl size=8311870 sha256=a9cba1b90cf757ac3ba5b2a518f1cc2daacd5adda08c36518e774ef19f648f79\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-b5qdd0oq/wheels/e7/9c/5b/e1a9c8007c343041e61cc484433d512ea9274272e3fcbe7c16\n",
      "Successfully built transformers\n",
      "Installing collected packages: tqdm, safetensors, regex, fsspec, huggingface-hub, tokenizers, transformers\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.4.0\n",
      "    Uninstalling fsspec-2023.4.0:\n",
      "      Successfully uninstalled fsspec-2023.4.0\n",
      "Successfully installed fsspec-2023.12.2 huggingface-hub-0.20.2 regex-2023.12.25 safetensors-0.4.1 tokenizers-0.15.0 tqdm-4.66.1 transformers-4.37.0.dev0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1581 B]\n",
      "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [643 kB]\n",
      "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu jammy InRelease [270 kB]\n",
      "Get:5 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [44.0 kB]\n",
      "Get:6 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [1582 kB]\n",
      "Get:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
      "Get:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [28.5 kB]\n",
      "Get:9 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1332 kB]\n",
      "Get:10 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1047 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 Packages [1792 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu jammy/restricted amd64 Packages [164 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 Packages [266 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu jammy/universe amd64 Packages [17.5 MB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1307 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [49.8 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1611 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1606 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [28.1 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [50.4 kB]\n",
      "Fetched 29.7 MB in 6s (5319 kB/s)\n",
      "Reading package lists...\n",
      "Collecting vllm\n",
      "  Downloading vllm-0.2.7-cp310-cp310-manylinux1_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting ninja (from vllm)\n",
      "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from vllm) (5.9.6)\n",
      "Collecting ray>=2.5.1 (from vllm)\n",
      "  Downloading ray-2.9.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting sentencepiece (from vllm)\n",
      "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from vllm) (1.24.1)\n",
      "Collecting torch==2.1.2 (from vllm)\n",
      "  Downloading torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: transformers>=4.36.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (4.37.0.dev0)\n",
      "Collecting xformers==0.0.23.post1 (from vllm)\n",
      "  Downloading xformers-0.0.23.post1-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
      "Collecting fastapi (from vllm)\n",
      "  Downloading fastapi-0.108.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting uvicorn[standard] (from vllm)\n",
      "  Downloading uvicorn-0.25.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting pydantic==1.10.13 (from vllm)\n",
      "  Downloading pydantic-1.10.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (149 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aioprometheus[starlette] (from vllm)\n",
      "  Downloading aioprometheus-23.12.0-py3-none-any.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic==1.10.13->vllm) (4.4.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->vllm) (3.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->vllm) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->vllm) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->vllm) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->vllm) (2023.12.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.1.2->vllm)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m184.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.1.2->vllm)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m157.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.1.2->vllm)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.1.2->vllm)\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.1.2->vllm)\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.1.2->vllm)\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.1.2->vllm)\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m124.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.1.2->vllm)\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.1.2->vllm)\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.18.1 (from torch==2.1.2->vllm)\n",
      "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.1.2->vllm)\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->vllm) (2.1.0)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.2->vllm)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting click>=7.0 (from ray>=2.5.1->vllm)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray>=2.5.1->vllm) (4.19.2)\n",
      "Collecting msgpack<2.0.0,>=1.0.0 (from ray>=2.5.1->vllm)\n",
      "  Downloading msgpack-1.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ray>=2.5.1->vllm) (23.2)\n",
      "Collecting protobuf!=3.19.5,>=3.15.3 (from ray>=2.5.1->vllm)\n",
      "  Downloading protobuf-4.25.1-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray>=2.5.1->vllm) (6.0.1)\n",
      "Collecting aiosignal (from ray>=2.5.1->vllm)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting frozenlist (from ray>=2.5.1->vllm)\n",
      "  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray>=2.5.1->vllm) (2.31.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.36.0->vllm) (0.20.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.36.0->vllm) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.36.0->vllm) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.36.0->vllm) (0.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.36.0->vllm) (4.66.1)\n",
      "Collecting orjson (from aioprometheus[starlette]->vllm)\n",
      "  Downloading orjson-3.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting quantile-python>=1.1 (from aioprometheus[starlette]->vllm)\n",
      "  Downloading quantile-python-1.1.tar.gz (2.9 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting starlette>=0.14.2 (from aioprometheus[starlette]->vllm)\n",
      "  Downloading starlette-0.34.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Downloading starlette-0.32.0.post1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting typing-extensions>=4.2.0 (from pydantic==1.10.13->vllm)\n",
      "  Downloading typing_extensions-4.9.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting h11>=0.8 (from uvicorn[standard]->vllm)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting httptools>=0.5.0 (from uvicorn[standard]->vllm)\n",
      "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting python-dotenv>=0.13 (from uvicorn[standard]->vllm)\n",
      "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]->vllm)\n",
      "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]->vllm)\n",
      "  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]->vllm)\n",
      "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette>=0.14.2->aioprometheus[starlette]->vllm) (4.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.2->vllm) (2.1.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray>=2.5.1->vllm) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray>=2.5.1->vllm) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray>=2.5.1->vllm) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray>=2.5.1->vllm) (0.12.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ray>=2.5.1->vllm) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray>=2.5.1->vllm) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray>=2.5.1->vllm) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray>=2.5.1->vllm) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.2->vllm) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette>=0.14.2->aioprometheus[starlette]->vllm) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette>=0.14.2->aioprometheus[starlette]->vllm) (1.1.3)\n",
      "Downloading vllm-0.2.7-cp310-cp310-manylinux1_x86_64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m186.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-1.10.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m137.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading xformers-0.0.23.post1-cp310-cp310-manylinux2014_x86_64.whl (213.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ray-2.9.0-cp310-cp310-manylinux2014_x86_64.whl (64.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading fastapi-0.108.0-py3-none-any.whl (92 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m110.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m114.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading msgpack-1.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (530 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m530.8/530.8 kB\u001b[0m \u001b[31m148.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.1-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m116.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading starlette-0.32.0.post1-py3-none-any.whl (70 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.0/70.0 kB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
      "Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m115.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m200.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aioprometheus-23.12.0-py3-none-any.whl (31 kB)\n",
      "Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m105.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading orjson-3.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uvicorn-0.25.0-py3-none-any.whl (60 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.3/60.3 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m118.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: quantile-python\n",
      "  Building wheel for quantile-python (setup.py): started\n",
      "  Building wheel for quantile-python (setup.py): finished with status 'done'\n",
      "  Created wheel for quantile-python: filename=quantile_python-1.1-py3-none-any.whl size=3443 sha256=e41966f9f7c1219101efa7c92ed798fe915c5b684c84943ae827f91ab5f0a196\n",
      "  Stored in directory: /root/.cache/pip/wheels/6d/f4/0a/0e7d01548a005f9f3fa23101f071d248da052f2a9bf2fe11c6\n",
      "Successfully built quantile-python\n",
      "Installing collected packages: sentencepiece, quantile-python, ninja, websockets, uvloop, typing-extensions, python-dotenv, protobuf, orjson, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, msgpack, httptools, h11, frozenlist, click, watchfiles, uvicorn, starlette, pydantic, nvidia-cusparse-cu12, nvidia-cudnn-cu12, aiosignal, aioprometheus, nvidia-cusolver-cu12, fastapi, torch, ray, xformers, vllm\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.4.0\n",
      "    Uninstalling typing_extensions-4.4.0:\n",
      "      Successfully uninstalled typing_extensions-4.4.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.1.0+cu118\n",
      "    Uninstalling torch-2.1.0+cu118:\n",
      "      Successfully uninstalled torch-2.1.0+cu118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\n",
      "torchvision 0.16.0+cu118 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed aioprometheus-23.12.0 aiosignal-1.3.1 click-8.1.7 fastapi-0.108.0 frozenlist-1.4.1 h11-0.14.0 httptools-0.6.1 msgpack-1.0.7 ninja-1.11.1.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 orjson-3.9.10 protobuf-4.25.1 pydantic-1.10.13 python-dotenv-1.0.0 quantile-python-1.1 ray-2.9.0 sentencepiece-0.1.99 starlette-0.32.0.post1 torch-2.1.2 typing-extensions-4.9.0 uvicorn-0.25.0 uvloop-0.19.0 vllm-0.2.7 watchfiles-0.21.0 websockets-12.0 xformers-0.0.23.post1\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.34.14-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting botocore<1.35.0,>=1.34.14 (from boto3)\n",
      "  Downloading botocore-1.34.14-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3)\n",
      "  Downloading s3transfer-0.10.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.14->boto3) (2.8.2)\n",
      "Requirement already satisfied: urllib3<2.1,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.14->boto3) (1.26.13)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.14->boto3) (1.16.0)\n",
      "Downloading boto3-1.34.14-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading botocore-1.34.14-py3-none-any.whl (11.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading s3transfer-0.10.0-py3-none-any.whl (82 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: jmespath, botocore, s3transfer, boto3\n",
      "Successfully installed boto3-1.34.14 botocore-1.34.14 jmespath-1.0.1 s3transfer-0.10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a89cd9199a8649cd94961c8fc65f656a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/596 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 01-07 23:42:13 llm_engine.py:70] Initializing an LLM engine with config: model='mistralai/Mistral-7B-Instruct-v0.2', tokenizer='mistralai/Mistral-7B-Instruct-v0.2', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, quantization=None, enforce_eager=False, seed=0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ef43d78f8bb434eb689f9f51f22bb23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.46k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10cc00c073584c4e83134d9f4a2743a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "562e55090ecc41308571d91205e67efd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b56e8442631449c09c0f144e398ba245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfdc792ac60748ee99769fb6b879e7a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "506d06aa55fe4ea0940324c3aa9f95bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00001-of-00003.bin:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43c0cdc98efb4daea8e2630c381d5563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00002-of-00003.bin:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75f5e0c100714142b2815452baea66e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00003-of-00003.bin:   0%|          | 0.00/5.06G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0d0537ab15f491d922d79ddc95b7e9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb31c7fc1f264be1a033119adb189ca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 01-07 23:42:49 llm_engine.py:275] # GPU blocks: 27161, # CPU blocks: 2048\n",
      "INFO 01-07 23:42:51 model_runner.py:501] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 01-07 23:42:51 model_runner.py:505] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode.\n",
      "INFO 01-07 23:42:54 model_runner.py:547] Graph capturing finished in 4 secs.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "subprocess_commands = [\n",
    "    'pip install  git+https://github.com/huggingface/transformers.git',\n",
    "    'apt-get update -y',\n",
    "    'pip install vllm',\n",
    "    'pip install boto3'\n",
    "\n",
    "]\n",
    "    \n",
    "for command in subprocess_commands:\n",
    "    subprocess.run(command, shell=True)\n",
    "\n",
    "\n",
    "# import runpod\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import torch\n",
    "import re\n",
    "from transformers import DonutProcessor, VisionEncoderDecoderModel\n",
    "import json  # Import json for creating JSON objects\n",
    "import requests\n",
    "import logging\n",
    "import boto3\n",
    "\n",
    "\n",
    "from vllm import LLM, SamplingParams\n",
    "llm = LLM(model=\"mistralai/Mistral-7B-Instruct-v0.2\", dtype=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0a97361-e6d1-4d3c-96ef-cd5658ee5cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "############## JSON #######################\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "def read_json_transcript(file_path):\n",
    "    \"\"\"Reads a JSON formatted transcript file and returns its content as a JSON object.\"\"\"\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            json_data = json.load(file)\n",
    "        return json_data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "# file_path = \"workspace/01_02_2024_09_28_AM_Rosemary_Marin.json\"\n",
    "# transcript_data = read_json_transcript(file_path)\n",
    "# if transcript_data:\n",
    "#     print(json.dumps(transcript_data, indent=2))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######## LLM #########\n",
    "\n",
    "\n",
    "def generate_text_Transcript(file_path):\n",
    "    \"\"\"Reads the content of a JSON file as text and returns it.\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            transcript_text = file.read()\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {file_path}: {e}\")\n",
    "        return None\n",
    "    \n",
    "    transcript_json_string = json.dumps(transcript_text, indent=2)\n",
    "\n",
    "    # Breaking down the f-string into smaller parts\n",
    "    prompt_header = '[INST] Analyze the provided call transcript and extract interactions relevant to each specified question in the customer service guide. For each question, identify and extract the corresponding segments from the transcript where the agent\\'s actions or responses align with the criteria of the question. Format the output as a JSON object for each question, including the relevant segment IDs and text excerpts from the transcript. The JSON structure should be as follows:\\n\\n'\n",
    "    prompt_questions = 'Questions:\\n\\n1. Call Opening\\n2. Greeting\\n3. Verification\\n4. Callback\\n5. Acknowledgement\\n6. Willingness to Assist\\n7. Professionalism and Confidence\\n8. Take Ownership of the Calls\\n9. Dead Air & Hold\\n10. Customer Experience\\n11. Active Listening\\n12. Expertise\\n13. Speed\\n\\n'\n",
    "    prompt_json = 'JSON transcript:\\n\\n'\n",
    "    \n",
    "    prompt_2 = prompt_header + prompt_questions + prompt_json + '\\n[/INST] \\n' + transcript_json_string\n",
    "\n",
    "\n",
    "\n",
    "    sampling_params = SamplingParams(\n",
    "        temperature=0.1,  # Allows for a balance between randomness and determinism\n",
    "        top_p=1,        # Ensures a good range of token possibilities\n",
    "        top_k=-1,         # Focuses on the top 50 tokens for each choice\n",
    "        use_beam_search=False,\n",
    "        # presence_penalty=0.1,  # Slightly encourages the use of new tokens\n",
    "        # frequency_penalty=0.1,  # Slightly discourages repetitive tokens\n",
    "        # repetition_penalty=1.1, # Helps prevent echoing of prompt content\n",
    "         # best_of=3,        # Generates multiple sequences to choose the best one\n",
    "         # n=1,              # Returns the single best sequence\n",
    "         max_tokens=5000,   # Sets a reasonable limit for the output length\n",
    "         early_stopping=False  # Stops generation when a complete response is formed\n",
    ")\n",
    "\n",
    "    print(\"Prompt 2 \\n\")\n",
    "    print(prompt_2)\n",
    "    print(\"\\n\")\n",
    "    print(\"OUTPUT:\")\n",
    "    outputs = llm.generate(prompt_2, sampling_params)\n",
    "\n",
    "    if outputs and len(outputs) > 0:\n",
    "        generated_text2 = outputs[0].outputs[0].text\n",
    "    else:\n",
    "        generated_text2 = \"No output generated\"\n",
    "\n",
    "    print(generated_text2)\n",
    "\n",
    "    # Clean the generated text to fix common JSON issues\n",
    "    #cleaned_text=generated_text2\n",
    "    cleaned_text = clean_json_text(generated_text2)\n",
    "\n",
    "    # Validate and return the cleaned JSON\n",
    "    try:\n",
    "        parsed_json = json.loads(cleaned_text)\n",
    "        print(\"Valid Json ok\")\n",
    "        return cleaned_text  # Return the valid JSON text\n",
    "    except json.JSONDecodeError:\n",
    "        error_message = \"Generated text is not valid JSON even after cleaning.\"\n",
    "        print(error_message)\n",
    "        return error_message  # You might want to return an error message or a default JSON structure\n",
    "\n",
    "\n",
    "def clean_json_text(text):\n",
    "    # Try to extract JSON structure\n",
    "    # This regex looks for the pattern that starts with '[' or '{', and ends with ']' or '}'\n",
    "    # It's a basic attempt to capture JSON-like structures\n",
    "    matches = re.findall(r'(\\[\\s*{.*?}\\s*\\]|\\{\\s*\".*?\"\\s*:\\s*.*?\\s*}\\])', text, re.DOTALL)\n",
    "    if matches:\n",
    "        # If multiple matches are found, choose the longest one (most likely to be complete)\n",
    "        cleaned_text = max(matches, key=len)\n",
    "    else:\n",
    "        # If no matches, return the original text for further handling\n",
    "        cleaned_text = text\n",
    "\n",
    "    # Remove extra whitespaces inside the JSON string (except in values to preserve formatting like \"356,650\")\n",
    "    cleaned_text = re.sub(r'\\s*(,|\\[|\\]|\\{|\\})\\s*', r'\\1', cleaned_text)\n",
    "    cleaned_text = re.sub(r'\\s*:\\s*', ': ', cleaned_text)  # Ensure space after colon\n",
    "\n",
    "    # Additional cleaning rules can be added here based on observed anomalies\n",
    "\n",
    "    return cleaned_text.strip()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##############################\n",
    "########## START #############\n",
    "##############################\n",
    "\n",
    "def handler(event):\n",
    "    print(\"Event received:\", event)\n",
    "\n",
    "    folder_path = event.get('input', {}).get('folder_path')\n",
    "    if not folder_path:\n",
    "        print(\"Folder path not provided in event.\")\n",
    "        return \"Error: Folder path not provided.\"\n",
    "\n",
    "\n",
    "    ############ AWS ######################\n",
    "\n",
    "    # s3_path = f\"s3://bucketmlocr1/{folder_path}\"\n",
    "    # os.makedirs(folder_path, exist_ok=True)\n",
    "    # subprocess.run(['aws', 's3', 'sync', s3_path, folder_path], check=True)\n",
    "\n",
    "    # s3_client = boto3.client('s3')\n",
    "    \n",
    "    \n",
    "    ############ EXECUTE ######################\n",
    "\n",
    "    # s3_client = boto3.client('s3')\n",
    "\n",
    "    for file in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        file_name = os.path.splitext(file)[0]  # Extracts file name without extension\n",
    "\n",
    "        if file.endswith(\".json\"):\n",
    "\n",
    "            # Generate JSON \n",
    "            generated_text2 = generate_text_Transcript(file_path)\n",
    "            #print(generated_text2)\n",
    "           \n",
    "            # Save the outputs to text files\n",
    "            # with open(f\"{folder_path}/items_{file_name}.txt\", \"w\") as items_file:\n",
    "            #     items_file.write(generated_text2)\n",
    "            # with open(f\"{folder_path}/regex_{file_name}.txt\", \"w\") as regex_file:\n",
    "            #     regex_file.write(final_date)\n",
    "\n",
    "            ############# RESPONSE ######################\n",
    "            \n",
    "            # Upload the files to the same S3 folder\n",
    "            # s3_client.upload_file(f\"{folder_path}/items_{file_name}.txt\", \"bucketmlocr1\", f\"{folder_path}/items_{file_name}.txt\")\n",
    "            # s3_client.upload_file(f\"{folder_path}/regex_{file_name}.txt\", \"bucketmlocr1\", f\"{folder_path}/regex_{file_name}.txt\")\n",
    "\n",
    "   \n",
    "    return \"Done\"\n",
    "        \n",
    "\n",
    "# runpod.serverless.start({\n",
    "#     \"handler\": handler\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "250956b8-b6ec-4ae0-ab13-22b0b7cb83c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event received: {'input': {'folder_path': './'}}\n",
      "Prompt 2 \n",
      "\n",
      "[INST] Analyze the provided call transcript and extract interactions relevant to each specified question in the customer service guide. For each question, identify and extract the corresponding segments from the transcript where the agent's actions or responses align with the criteria of the question. Format the output as a JSON object for each question, including the relevant segment IDs and text excerpts from the transcript. The JSON structure should be as follows:\n",
      "\n",
      "Questions:\n",
      "\n",
      "1. Call Opening\n",
      "2. Greeting\n",
      "3. Verification\n",
      "4. Callback\n",
      "5. Acknowledgement\n",
      "6. Willingness to Assist\n",
      "7. Professionalism and Confidence\n",
      "8. Take Ownership of the Calls\n",
      "9. Dead Air & Hold\n",
      "10. Customer Experience\n",
      "11. Active Listening\n",
      "12. Expertise\n",
      "13. Speed\n",
      "\n",
      "JSON transcript:\n",
      "\n",
      "\n",
      "[/INST] \n",
      "\"\\ufeff{\\n\\\"transcriptSegments\\\":\\n[\\n\\n{\\n \\\"segmentId\\\": 1,\\n\\\"segment\\\": \\\"00:00:00,620 - 00:00:06,160\\\",\\n\\\"speaker\\\": \\\"Speaker 0\\\", \\n\\\"text\\\": \\\"Thank you for calling PetSupermarket, this is Rosemary, may I know your name please?\\\"\\n},\\n\\n{\\n \\\"segmentId\\\": 2,\\n\\\"segment\\\": \\\"00:00:07,660 - 00:00:08,940\\\",\\n\\\"speaker\\\": \\\"Speaker 1\\\", \\n\\\"text\\\": \\\"Sure, it's Danielle Rodriguez.\\\"\\n},\\n\\n{\\n \\\"segmentId\\\": 3,\\n\\\"segment\\\": \\\"00:00:10,100 - 00:00:11,700\\\",\\n\\\"speaker\\\": \\\"Speaker 0\\\", \\n\\\"text\\\": \\\"Hello Danielle, how can I help you today?\\\"\\n},\\n\\n{\\n \\\"segmentId\\\": 4,\\n\\\"segment\\\": \\\"00:00:13,560 - 00:00:32,060\\\",\\n\\\"speaker\\\": \\\"Speaker 1\\\", \\n\\\"text\\\": \\\"I placed an order 6 days ago and they sent me the tracking via email from 1229. And when I track it, it still says that FedEx doesn't even have the package. It just says that the label was created. I just wanted to see what the story is because I'm running out of food here.\\\"\\n},\\n\\n{\\n \\\"segmentId\\\": 5,\\n\\\"segment\\\": \\\"00:00:33,220 - 00:00:34,040\\\",\\n\\\"speaker\\\": \\\"Speaker 0\\\", \\n\\\"text\\\": \\\"Oh yes, of course.\\\"\\n},\\n\\n{\\n \\\"segmentId\\\": 6,\\n\\\"segment\\\": \\\"00:00:34,120 - 00:00:34,880\\\",\\n\\\"speaker\\\": \\\"Speaker 1\\\", \\n\\\"text\\\": \\\"Do I have an order number?\\\"\\n},\\n\\n{\\n \\\"segmentId\\\": 7,\\n\\\"segment\\\": \\\"00:00:36,120 - 00:00:38,100\\\",\\n\\\"speaker\\\": \\\"Speaker 0\\\", \\n\\\"text\\\": \\\"No, go ahead.\\\"\\n},\\n\\n{\\n \\\"segmentId\\\": 8,\\n\\\"segment\\\": \\\"00:00:39,620 - 00:00:40,700\\\",\\n\\\"speaker\\\": \\\"Speaker 1\\\", \\n\\\"text\\\": \\\"Did you want the order number?\\\"\\n},\\n\\n{\\n \\\"segmentId\\\": 9,\\n\\\"segment\\\": \\\"00:00:42,280 - 00:00:47,520\\\",\\n\\\"speaker\\\": \\\"Speaker 0\\\", \\n\\\"text\\\": \\\"Yeah, can you please give me the order number or your email address? Just to make sure.\\\"\\n},\\n\\n{\\n \\\"segmentId\\\": 10,\\n\\\"segment\\\": \\\"00:00:47,520 - 00:00:54,440\\\",\\n\\\"speaker\\\": \\\"Speaker 1\\\", \\n\\\"text\\\": \\\"The order number is 00742084.\\\"\\n},\\n\\n{\\n \\\"segmentId\\\": 11,\\n\\\"segment\\\": \\\"00:00:55,540 - 00:01:14,320\\\",\\n\\\"speaker\\\": \\\"Speaker 0\\\", \\n\\\"text\\\": \\\"Thank you so much for that information. Can you please? And I'm so sorry to hear that you didn't receive your product and also doesn't have any movement. you're tracking. Can you please give me just a few minutes on hold? Well, I'm checking in here about your order and I'll be back with you, okay?\\\"\\n},\\n\\n{\\n \\\"segmentId\\\": 12,\\n\\\"segment\\\": \\\"00:01:15,400 - 00:01:15,940\\\",\\n\\\"speaker\\\": \\\"Speaker 1\\\", \\n\\\"text\\\": \\\"Okay, thank you.\\\"\\n},\\n\\n{\\n \\\"segmentId\\\": 13,\\n\\\"segment\\\": \\\"00:01:17,520 - 00:04:12,260\\\",\\n\\\"speaker\\\": \\\"Speaker 0\\\", \\n\\\"text\\\": \\\"Thank you. Thank you. Thank you. Thank you. Thank you. Hello, Daniel. I'm back. Thank you so much for you waiting.\\\"\\n},\\n\\n{\\n \\\"segmentId\\\": 14,\\n\\\"segment\\\": \\\"00:04:13,380 - 00:04:13,940\\\",\\n\\\"speaker\\\": \\\"Speaker 1\\\", \\n\\\"text\\\": \\\"No problem.\\\"\\n},\\n\\n{\\n \\\"segmentId\\\": 15,\\n\\\"segment\\\": \\\"00:04:14,620 - 00:04:50,400\\\",\\n\\\"speaker\\\": \\\"Speaker 0\\\", \\n\\\"text\\\": \\\"Okay, so I was checking in here about your order. The order is in label created but since you placed the order on the 27th, our stores and the fulfillment places, they have up to two days to be fulfilled the order and sent it. Today is the first business day since the label was created so it should be sent in this week. The time to be delivered the order is between two to five business days. So we are still on the time frame so I recommend to you to wait a little more. It will be sent to you in this week.\\\"\\n},\\n\\n{\\n \\\"segmentId\\\": 16,\\n\\\"segment\\\": \\\"00:04:50,400 - 00:04:51,120\\\",\\n\\\"speaker\\\": \\\"Speaker 1\\\", \\n\\\"text\\\": \\\"I don't have a choice.\\\"\\n},\\n\\n{\\n \\\"segmentId\\\": 17,\\n\\\"segment\\\": \\\"00:04:51,380 - 00:05:02,320\\\",\\n\\\"speaker\\\": \\\"Speaker 0\\\", \\n\\\"text\\\": \\\"In case that in Friday you didn't receive your order, you can call us and we can check in here if we can receive it or refund you for your order, okay? Okay. No worries.\\\"\\n},\\n\\n{\\n \\\"segmentId\\\": 18,\\n\\\"segment\\\": \\\"00:05:02,620 - 00:05:03,500\\\",\\n\\\"speaker\\\": \\\"Speaker 1\\\", \\n\\\"text\\\": \\\"Alright, thank you.\\\"\\n},\\n\\n{\\n \\\"segmentId\\\": 19,\\n\\\"segment\\\": \\\"00:05:04,000 - 00:05:05,760\\\",\\n\\\"speaker\\\": \\\"Speaker 0\\\", \\n\\\"text\\\": \\\"Thanks to you. If there may be anything else that you want to add?\\\"\\n}\\n],\\n\\\"name\\\": \\\"01_02_2024_09_28_AM_Rosemary_Marin.json\\\"}\\n\"\n",
      "\n",
      "\n",
      "OUTPUT:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[\n",
      "{\n",
      "\"Questions\": [\n",
      "{\n",
      "\"question\": \"Call Opening\"\n",
      "},\n",
      "{\n",
      "\"question\": \"Greeting\"\n",
      "}\n",
      "],\n",
      "\"relevantSegments\": [\n",
      "{\n",
      "\"segmentId\": 1,\n",
      "\"text\": \"Thank you for calling PetSupermarket, this is Rosemary, may I know your name please?\"\n",
      "},\n",
      "{\n",
      "\"segmentId\": 2,\n",
      "\"text\": \"Sure, it's Danielle Rodriguez.\"\n",
      "}\n",
      "]\n",
      "},\n",
      "{\n",
      "\"Questions\": [\n",
      "{\n",
      "\"question\": \"Verification\"\n",
      "}\n",
      "],\n",
      "\"relevantSegments\": [\n",
      "{\n",
      "\"segmentId\": 6,\n",
      "\"text\": \"Do I have an order number?\"\n",
      "},\n",
      "{\n",
      "\"segmentId\": 9,\n",
      "\"text\": \"Did you want the order number?\"\n",
      "},\n",
      "{\n",
      "\"segmentId\": 10,\n",
      "\"text\": \"The order number is 00742084.\"\n",
      "}\n",
      "]\n",
      "},\n",
      "{\n",
      "\"Questions\": [\n",
      "{\n",
      "\"question\": \"Callback\"\n",
      "}\n",
      "],\n",
      "\"relevantSegments\": [\n",
      "{\n",
      "\"segmentId\": 13,\n",
      "\"text\": \"Thank you. Thank you. Thank you. Thank you. Thank you. Hello, Daniel. I'm back.\"\n",
      "}\n",
      "]\n",
      "},\n",
      "{\n",
      "\"Questions\": [\n",
      "{\n",
      "\"question\": \"Acknowledgement\"\n",
      "}\n",
      "],\n",
      "\"relevantSegments\": [\n",
      "{\n",
      "\"segmentId\": 5,\n",
      "\"text\": \"Oh yes, of course.\"\n",
      "},\n",
      "{\n",
      "\"segmentId\": 14,\n",
      "\"text\": \"No problem.\"\n",
      "}\n",
      "]\n",
      "},\n",
      "{\n",
      "\"Questions\": [\n",
      "{\n",
      "\"question\": \"Professionalism and Confidence\"\n",
      "}\n",
      "],\n",
      "\"relevantSegments\": [\n",
      "{\n",
      "\"segmentId\": 7,\n",
      "\"text\": \"No, go ahead.\"\n",
      "},\n",
      "{\n",
      "\"segmentId\": 15,\n",
      "\"text\": \"Thank you. Thank you. Thank you. Thank you. Thank you. Hello, Daniel. I'm back.\"\n",
      "}\n",
      "]\n",
      "},\n",
      "{\n",
      "\"Questions\": [\n",
      "{\n",
      "\"question\": \"Take Ownership of the Calls\"\n",
      "}\n",
      "],\n",
      "\"relevantSegments\": [\n",
      "{\n",
      "\"segmentId\": 11,\n",
      "\"text\": \"Thank you so much for that information. Can you please? And I'm so sorry to hear that you didn't receive your product and also doesn't have any movement. you're tracking. Can you please give me just a few minutes on hold? Well, I'm checking in here about your order and I'll be back with you, okay?\"\n",
      "}\n",
      "]\n",
      "},\n",
      "{\n",
      "\"Questions\": [\n",
      "{\n",
      "\"question\": \"Dead Air & Hold\"\n",
      "}\n",
      "],\n",
      "\"relevantSegments\": [\n",
      "{\n",
      "\"segmentId\": 11,\n",
      "\"text\": \"Can you please give me just a few minutes on hold? Well, I'm checking in here about your order and I'll be back with you, okay?\"\n",
      "}\n",
      "]\n",
      "},\n",
      "{\n",
      "\"Questions\": [\n",
      "{\n",
      "\"question\": \"Customer Experience\"\n",
      "}\n",
      "],\n",
      "\"relevantSegments\": [\n",
      "{\n",
      "\"segmentId\": 15,\n",
      "\"text\": \"Thank you. Thank you. Thank you. Thank you. Thank you. Hello, Daniel. I'm back. Thank you so much for you waiting. The order is in label created but since you placed the order on the 27th, our stores and the fulfillment places, they have up to two days to be fulfilled the order and sent it. Today is the first business day since the label was created so it should be sent in this week. The time to be delivered the order is between two to five business days. So we are still on the time frame so I recommend to you to wait a little more. It will be sent to you in this week.\"\n",
      "}\n",
      "]\n",
      "},\n",
      "{\n",
      "\"Questions\": [\n",
      "{\n",
      "\"question\": \"Active Listening\"\n",
      "}\n",
      "],\n",
      "\"relevantSegments\": [\n",
      "{\n",
      "\"segmentId\": 4,\n",
      "\"text\": \"I placed an order 6 days ago and they sent me the tracking via email from 1229. And when I track it, it still says that FedEx doesn't even have the package. It just says that the label was created. I just wanted to see what the story is because I'm running out of food here.\"\n",
      "}\n",
      "]\n",
      "},\n",
      "{\n",
      "\"Questions\": [\n",
      "{\n",
      "\"question\": \"Expertise\"\n",
      "}\n",
      "],\n",
      "\"relevantSegments\": [\n",
      "{\n",
      "\"segmentId\": 15,\n",
      "\"text\": \"The order is in label created but since you placed the order on the 27th, our stores and the fulfillment places, they have up to two days to be fulfilled the order and sent it. Today is the first business day since the label was created so it should be sent in this week. The time to be delivered the order is between two to five business days. So we are still on the time frame so I recommend to you to wait a little more. It will be sent to you in this week.\"\n",
      "}\n",
      "]\n",
      "},\n",
      "{\n",
      "\"Questions\": [\n",
      "{\n",
      "\"question\": \"Speed\"\n",
      "}\n",
      "],\n",
      "\"relevantSegments\": [\n",
      "{\n",
      "\"segmentId\": 13,\n",
      "\"text\": \"Thank you. Thank you. Thank you. Thank you. Thank you. Hello, Daniel. I'm back.\"\n",
      "}\n",
      "]\n",
      "}\n",
      "]\n",
      "\n",
      "This JSON object contains the call transcript, segmented into relevant segments for each question in the customer service guide. The \"relevantSegments\" array contains the segment IDs and text excerpts from the transcript that align with the criteria of each question.\n",
      "Valid Json ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Done'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event = {\n",
    "            \"input\": {\n",
    "                \"folder_path\": \"./\"  # Pass the folder path\n",
    "            }\n",
    "        }\n",
    "handler(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e597d063-3609-4bd2-badb-80497fdf9f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "event = {\n",
    "            \"input\": {\n",
    "                \"folder_path\": \"processing/facturas-ocr/4. Facturas de venta escaneadas/1. Enero 2016/ENERO 1\"  # Pass the folder path\n",
    "            }\n",
    "        }\n",
    "handler(event)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
